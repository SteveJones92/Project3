[
  {
    "objectID": "pages/EDA.html#exploratory-data-analysis",
    "href": "pages/EDA.html#exploratory-data-analysis",
    "title": "EDA",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\n\n# load data\ndata &lt;- read.csv(\"../data/diabetes_binary_health_indicators_BRFSS2015.csv\")\n\n\nCheck missing values\n\nsum(is.na(data))\n\n[1] 0\n\n\n\nThere are no missing values in the data.\n\n\n\nDiabetes proportion\n\nn &lt;- nrow(data) # 253680 items\nn\ntable(data$Diabetes_binary) / n\n\n[1] 253680\n\n       0        1 \n0.860667 0.139333 \n\n\n\nThere are 25368 rows in the data. Out of this, it is seen that 14% of the data are diabetes=true and 86% do not have diabetes. This means that if the guess is just to put no diabetes for everything, the accuracy would be 86%, and any model should do better than this.\n\n\n\nExploring Yes/No Categories (14 out of 21)\n\nhelper &lt;- function(category) {\n  # finds the proportions of the category for yes/no categories\n  # finds the proportion of each combination\n  # finds the percentages of diabetes based on the category\n  prop &lt;- table(data[[category]]) / n\n  ct &lt;- table(ifelse(data$Diabetes_binary == 1, \"Diabetes\", \"NoDiabetes\" ),\n              ifelse(data[[category]] == 1, category, paste0(\"No\", category))) / n\n  explained &lt;- t(t(ct) / ( ct[1,] + ct[2,]))\n  max(explained[,1]) * prop[2] + max(explained[,2]) * prop[1]\n  print(prop)\n  print(ct)\n  print(explained)\n}\n\n\nFrequent Items\n\nhelper(\"HighBP\")\n\n\n        0         1 \n0.5709989 0.4290011 \n            \n                 HighBP   NoHighBP\n  Diabetes   0.10487228 0.03446074\n  NoDiabetes 0.32412882 0.53653816\n            \n                 HighBP   NoHighBP\n  Diabetes   0.24445690 0.06035167\n  NoDiabetes 0.75554310 0.93964833\n\n\n\nThe split of the data on high blood pressure vs not high blood pressure is 57% and 42%, respectively. We can see of the 57% for 0 HighBP, 53.6% is no diabetes and 3.4% is diabetes. The proportion here is 93.9% and 6%, meaning if we flat-out guessed no diabetes for this NoHighBP items, we’d get a 93.9% accuracy. But we want to learn about the more rare class of diabetes. So a good thing to look at is the ratio between NoHighBP and HighBP. If we had diabetes, we’d be about 4x more likely to have HighBP. Other items in this category are HighChol, PhysActivity, Smoker, and DiffWalk.\n\n\n\nInfrequent Items\n\nhelper(\"CholCheck\")\n\n\n        0         1 \n0.0373305 0.9626695 \n            \n                CholCheck  NoCholCheck\n  Diabetes   0.1383830022 0.0009500158\n  NoDiabetes 0.8242865027 0.0363804793\n            \n              CholCheck NoCholCheck\n  Diabetes   0.14374923  0.02544879\n  NoDiabetes 0.85625077  0.97455121\n\n\n\nThere are a set of items here where most of the rows are 1 value. Almost all respondents (96%) has had a cholesterol check within the last 5 years. So even if we got info from this, it wouldn’t apply in most cases. That said, if you did get info, the ratio is large (~7x). Other items in this category are Stroke, HeartDiseaseorAttack, and HvyAlcoholConsump.\n\n\n\nLittle to no information\n\nhelper(\"Fruits\")\nhelper(\"Sex\")\n\n\n        0         1 \n0.3657442 0.6342558 \n            \n                 Fruits   NoFruits\n  Diabetes   0.08157127 0.05776175\n  NoDiabetes 0.55268448 0.30798250\n            \n                Fruits  NoFruits\n  Diabetes   0.1286094 0.1579293\n  NoDiabetes 0.8713906 0.8420707\n\n        0         1 \n0.5596578 0.4403422 \n            \n                  NoSex        Sex\n  Diabetes   0.07257569 0.06675733\n  NoDiabetes 0.48708215 0.37358483\n            \n                 NoSex       Sex\n  Diabetes   0.1296787 0.1516033\n  NoDiabetes 0.8703213 0.8483967\n\n\n\nThese items don’t really have a spread of diabetes vs non-diabetes. Basically, if you knew someone was male or female, it wouldn’t tell you anything more about diabetes or not by itself. The same for Fruits, Veggies, AnyHealthcare, and NoDocbcCost. Now it’s possible that these proportions change in conjunction with another set of information (maybe fruits + high bp would have a better separation and fruit has typically high sugar content). It may be worth it to include in a tree build just for 1, to see if it makes a difference.\n\n\n\n\nExploring non-yes/no items of BMI, GenHlth, MentHlth, PhysHlth, Age, Education, Income\n\n# leftover BMI, GenHlth, MentHlth, PhysHlth, Age, Education, Income\npaste0(cor(data$MentHlth, data$Diabetes_binary), \" MentHlth\")\npaste0(cor(data$PhysHlth, data$Diabetes_binary), \" PhysHlth\")\npaste0(cor(data$GenHlth, data$Diabetes_binary), \" GenHlth\")\npaste0(cor(data$BMI, data$Diabetes_binary), \" BMI\")\npaste0(cor(data$Age, data$Diabetes_binary), \" Age\")\npaste0(cor(data$Education, data$Diabetes_binary), \" Education\")\npaste0(cor(data$Income, data$Diabetes_binary), \" Income\")\n\n[1] \"0.0693150826381003 MentHlth\"\n[1] \"0.171336700387463 PhysHlth\"\n[1] \"0.29356906307932 GenHlth\"\n[1] \"0.216843060203153 BMI\"\n[1] \"0.177441872167362 Age\"\n[1] \"-0.124455969216236 Education\"\n[1] \"-0.163918786800468 Income\"\n\n\n\nThe highest correlation is General Health (1 being best and 5 being worst). So higher age, thinking about physical or mental health, generally worse health ratings, and higher BMI have positive correlations (leading towards diabetes). Higher education and higher income lead towards not having diabetes. Let’s look at some plots.\n\n\nggplot(data, aes(x = Age, fill = factor(Diabetes_binary))) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nggplot(data, aes(x = Income, fill = factor(Diabetes_binary))) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nggplot(data, aes(x = Education, fill = factor(Diabetes_binary))) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nggplot(data, aes(x = GenHlth, fill = factor(Diabetes_binary))) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nggplot(data, aes(x = MentHlth, fill = factor(Diabetes_binary))) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nggplot(data, aes(x = PhysHlth, fill = factor(Diabetes_binary))) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nggplot(data, aes(x = BMI, fill = factor(Diabetes_binary))) +\n    geom_histogram(position = \"fill\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nhist(data$BMI, breaks = 20)\n\n\n\n\n\n\n\n\n\nAge, GenHlth, and BMI are generally supported as having an effect on the response. BMI is quite rare after values of 40, and with diabetes being a generally rare class, it makes sense for the chart to lose shape at the higher values. PhysHlth and MentHlth are not the best and likely represented a good amount through GenHlth reporting, so let’s just use that. As for education and income, they look viable to use, but don’t make a lot of sense for explainability of outcome. These are likely represented by way of effect of income on MentHlth for example (and many other categories, like needing to see a doctor but couldn’t past 12 month). These will intentionally not be used.\n\n\n\nBundling frequent and infrequent items (general idea of presenting with more items is more likely to suggest for diabetes). This is common in the health industry.\n\n# summing across the common items that have an effect\n# summing across the rare items that have an effect\ndata_fixed &lt;- data |&gt;\n  mutate(\n    count_common = rowSums(across(c(HighBP, HighChol, Smoker, PhysActivity, DiffWalk))),\n    count_rare = rowSums(across(c(CholCheck, Stroke, HeartDiseaseorAttack, HvyAlcoholConsump)))\n  ) |&gt;\n  select(-c(Fruits, Veggies, AnyHealthcare, NoDocbcCost, Income, Education, PhysHlth, MentHlth))\n\ntable(db = data_fixed$Diabetes_binary, common = data_fixed$count_common)\ntable(db = data_fixed$Diabetes_binary, rare = data_fixed$count_rare)\n\n   common\ndb      0     1     2     3     4     5\n  0  8094 63874 72014 49193 21853  3306\n  1   409  3039  8275 12248  9193  2182\n   rare\ndb       0      1      2      3      4\n  0   8159 177971  29100   3019     85\n  1    174  25047   8363   1738     24\n\n\n\nShowing the diabetes counts across the tallies of these common and rare items, we can see the ratios get smaller as more items are tacked on. It is typical practice in healthcare to have patients that present with higher number of red-flag factors to be more susceptible to other worse outcomes.\n\n\n\nConverting column structures to factors and numbers.\n\ndata_fixed_m &lt;- data_fixed |&gt;\n  mutate(\n    HighBP = factor(HighBP, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    HighChol = factor(HighChol, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    CholCheck = factor(CholCheck, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    Smoker = factor(Smoker, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    Stroke = factor(Stroke, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    HeartDiseaseorAttack = factor(HeartDiseaseorAttack, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    PhysActivity = factor(PhysActivity, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    HvyAlcoholConsump = factor(HvyAlcoholConsump, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    DiffWalk = factor(DiffWalk, levels = c(0, 1), labels = c(\"No\", \"Yes\")),\n    GenHlth = factor(GenHlth, levels = c(1, 2, 3, 4, 5), labels = c(\"Excellent\", \"Very Good\", \"Good\", \"Fair\", \"Poor\")),\n    Age = factor(Age, levels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13), labels = c(\"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\", \"45-49\", \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\", \"75-79\", \"80+\")),\n    Diabetes_binary = factor(Diabetes_binary, levels = c(0, 1), labels = c(\"No\", \"Yes\"))\n  )\nstr(data_fixed_m)\n\n'data.frame':   253680 obs. of  16 variables:\n $ Diabetes_binary     : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 2 1 ...\n $ HighBP              : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 2 2 2 2 2 2 1 ...\n $ HighChol            : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 1 2 2 1 2 2 1 ...\n $ CholCheck           : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 2 2 2 2 2 2 2 ...\n $ BMI                 : num  40 25 28 27 24 25 30 25 30 24 ...\n $ Smoker              : Factor w/ 2 levels \"No\",\"Yes\": 2 2 1 1 1 2 2 2 2 1 ...\n $ Stroke              : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ HeartDiseaseorAttack: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 2 1 ...\n $ PhysActivity        : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 2 2 2 1 2 1 1 ...\n $ HvyAlcoholConsump   : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ GenHlth             : Factor w/ 5 levels \"Excellent\",\"Very Good\",..: 5 3 5 2 2 2 3 3 5 2 ...\n $ DiffWalk            : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 1 1 1 1 2 2 1 ...\n $ Sex                 : num  0 0 0 0 0 1 0 0 0 1 ...\n $ Age                 : Factor w/ 13 levels \"18-24\",\"25-29\",..: 9 7 9 11 11 10 9 11 9 8 ...\n $ count_common        : num  4 2 3 2 3 4 2 5 4 0 ...\n $ count_rare          : num  1 0 1 1 1 1 1 1 2 1 ...\n\n\n\nAlmost all of the data are factors. Only BMI and the counts created are non-factors. Convert all to appropriate labels. Our data should be ready for sending to models for usage."
  },
  {
    "objectID": "pages/Modeling.html#building-2-models-predicting-diabetes_binary-using-log-loss-as-evaluation-metric",
    "href": "pages/Modeling.html#building-2-models-predicting-diabetes_binary-using-log-loss-as-evaluation-metric",
    "title": "Models",
    "section": "Building 2 Models predicting ‘Diabetes_binary’ using ‘log-loss’ as evaluation metric",
    "text": "Building 2 Models predicting ‘Diabetes_binary’ using ‘log-loss’ as evaluation metric\n\nlibrary(tidymodels)\nlibrary(parsnip)\n\n\nData split\n\n# set.seed(11)\n# data_split &lt;- initial_split(data_fixed_m, prop = 0.10, strata = Diabetes_binary)\n# data_train &lt;- training(data_split)\n# data_test &lt;- testing(data_split)\n# data_5_fold &lt;- vfold_cv(data_train, v=5, strata = Diabetes_binary)\n\n\n\nModel recipe\n\n# model_recipe &lt;- recipe(Diabetes_binary ~ BMI + Age + GenHlth + count_common + count_rare, data = data_train) |&gt;\n#   step_mutate(\n#     GenHlth = factor(GenHlth, ordered = TRUE),\n#     Age = factor(Age, ordered = TRUE)\n#   )\n#\n# model_recipe |&gt; prep() |&gt; bake(new_data = data_train)\n\n\n\nModel 1: Classification Tree\n\n# class_tree_spec &lt;- decision_tree(tree_depth = tune(), min_n = 5, cost_complexity = tune()) |&gt;\n#   set_engine(\"rpart\") |&gt;\n#   set_mode (\"classification\")\n\n\n\nModel 2: Random Forest\n\n# RF_spec &lt;- rand_forest(\n#   mtry = tune(),\n#   trees = tune()) |&gt;  # default is 500\n#   set_engine(\"ranger\", importance=\"impurity\") |&gt;\n#   set_mode(\"classification\")\n\n\nEDA Page"
  },
  {
    "objectID": "pages/EDA.html#to-modeling",
    "href": "pages/EDA.html#to-modeling",
    "title": "EDA",
    "section": "To Modeling",
    "text": "To Modeling"
  }
]